# Data

## Description

Our data is collected by a non-profit organization called [Epoch AI](https://epoch.ai/). From their (website)[https://epoch.ai/about], Epoch AI's mission is:

> Epoch AI is a multidisciplinary non-profit research institute investigating the future of artificial intelligence. We examine the driving forces behind AI and forecast its economic and societal impact. We emphasize making our research accessible through our reports, models and visualizations to help ground the discussion of AI on a solid empirical footing. Our goal is to create a healthy scientific environment, where claims about AI are discussed with the rigor they merit.

In the past, Epoch AI's work has been cited in [Our World in Data](https://ourworldindata.org/brief-history-of-ai), [Time Magazine](https://time.com/6300942/ai-progress-charts/), by [Google CEO Sundar Pichai](https://blog.google/technology/ai/bard-google-ai-search-updates/), and other reputable sources.

Generally, we frame our work in terms of inputs factors and output results and further subdivide this into input factors for AI models, input factors for AI companies, output results for AI models, and output results for AI companies:

- AI Models:
    - Inputs:
        - GPU Clusters
        - Compute Spend
    - Outputs:
        - Performance on model benchmarks
- AI Companies:
    - Inputs:
        - Staffing
        - Funding
    - Outputs:
        - Usage of AI tools
        - Revenue

### Collection Methods

Epoch AI collects data on variety of different components related to AI progress including hardware advancements, GPU cluster advancements, model releases, AI company funding, etc. For the most part, Epoch uses a mix of automated collections methods (for example, automatic updates of AI benchmark scores) and manual data collection from public sources of information (company blog posts, new posts, public satellite imagery). Here we link to the full set of data collection methodologies:

- [GPU Cluster Data](https://epoch.ai/data/gpu-clusters-documentation#inclusion)
- [AI Company Data](https://epoch.ai/data/ai-companies-documentation#inclusion)
- [AI Model Data](https://epoch.ai/data/ai-models-documentation#inclusion)
- [AI Benchmark Data](https://epoch.ai/benchmarks/about)

### Datasets Overview

| Title | Description | Frequency of Updates | Dimensions | Notes |
|-------|-------------|---------------------|------------|-------|
|  GPU Clusters     |    Dataset listing planned, existing, and previous GPU clusters         |         Daily            |      786 rows,  55 columns     |   Daily refreshes, but data may not necessarily be updated daily.    |
|  AI Companies     |      Various different datasets pertaining to AI company revenue, compute spend, staffing, funding rounds, user usage, and general information       |         Daily            |     Various datasets       |       |
|   AI Models    |     Dataset listing AI models over the years (including primitive models)        |         Daily            |     3000+ rows, 56 columns       |  Divided into "Frontier", "Notable", and "Large Scale" models   |
| AI Benchmark Data      |   A collection of different datasets of ML model performance on different benchmarks          |      not found               |     Various datasets       |       |

Please see links above for finer details on the datasets.

## Missing value analysis

### Compute Spend
```{r}
library(redav)

compute_spend <- read_csv("./Data/ai_companies_dataset/ai_companies_compute_spend.csv")

usage_rates <- read_csv("./Data/ai_companies_dataset/ai_companies_usage_reports.csv")

ai_models <- read_csv("./Data/ai_models_dataset/all_ai_models.csv")

fronteir_math <- read_csv("./Data/benchmark_dataset/frontiermath.csv")

gpu_cluster_ds <- read_csv("./Data/gpu_clusters_dataset/gpu_clusters.csv")


p1 <- plot_missing(compute_spend, max_cols = 10, num_char = 7, percent = FALSE)
p2 <- plot_missing(compute_spend, num_char = 2, percent = TRUE)
p1
p2
```

### Usage Rates

```{r}
p3 <- plot_missing(usage_rates, max_cols = 10, num_char = 7, percent = FALSE)
p4 <- plot_missing(usage_rates, num_char = 2, percent = TRUE)
p3
p4
```

### Frontier Math Benchmark

```{r}
p7 <- plot_missing(fronteir_math, max_cols = 10, num_char = 7, percent = FALSE)
p8 <- plot_missing(fronteir_math, num_char = 2, percent = TRUE)
p7
p8
```

### GPU Clusters & AI Models


## Other problems and limitations of the data
- inconsistent location format in the GPU cluster dataset
