[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Pulse: Exploring the Drivers of AI Development",
    "section": "",
    "text": "1 Introduction\nFrom it’s humble beginnings in the 1950s, and throught a cycle of dark and golder ages, AI finally exploded in the early 2020s with the introduction of large language models. Studying the history of AI development, we see breakthoughs resulting for innovations in various front. AlexNet in 2012 ushered in a new era of deep learning fueled by the availability of large datasets and shift towards GPU training. Five years later, in 2017, an algorithmic innovation, attenion and the transformer architecture, ushered in yet another era of AI, namely the era of large language models which is still experiencing rapid growth today.\nWhether it be hardware infrastructure, data quantity and quality, or algorithmic innovations, each of these factors has played an important role in the development of new AI techniques or as bottlenecks to said breakthroughs. In this project we aim to explore how these factors have changed over time in order to have an in-depth understanding of the driving forces behind AI development. With this understanding, we hope to be better able to understand where AI may be heading in the future.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nOur data is collected by an non-profit organization called Epoch AI. From their (website)[https://epoch.ai/about], Epoch AI’s mission is:\nIn the past, Epoch AI’s work has been cited in Our World in Data, Time Magazine, by Google CEO Sundar Pichai, and other reputable sources.\nGenerally, we frame our work in terms of inputs factors and output results and further subdivide this into input factors for AI models, input factors for AI companies, output results for AI models, and output results for AI companies:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.2 Missing value analysis",
    "text": "2.2 Missing value analysis",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "",
    "text": "Epoch AI is a multidisciplinary non-profit research institute investigating the future of artificial intelligence. We examine the driving forces behind AI and forecast its economic and societal impact. We emphasize making our research accessible through our reports, models and visualizations to help ground the discussion of AI on a solid empirical footing. Our goal is to create a healthy scientific environment, where claims about AI are discussed with the rigor they merit.\n\n\n\n\nAI Models:\n\nInputs:\n\nGPU Clusters\nCompute Spend\nHardware advacements\n\nOutpus:\n\nPerformance on model benchmarks\n\n\nAI Companies:\n\nInputs:\n\nStaffing\nFunding\n\nOutputs:\n\nUsage of AI tools\nRevenue\n\n\n\n\n2.1.1 Collection Methods\nEpoch AI collects data on variety of different components related to AI progress including hardware advancements, GPU cluster advanacements, model releases, AI company funding, etc. For the most part, Epoch uses a mix of automated collections methods (for example, automatic updates of AI benchmark scores) and manual data collection from public sources of information (company blog posts, new posts, public satellite imagery). Here we link to the full set of data collection methodologies:\n\nML Hardware Data\nGPU Cluster Data\nAI Company Data\nAI Model Data\nAI Benchmark Data\n\n\n\n2.1.2 Datasets Overview\n\n\n\n\n\n\n\n\n\n\nTitle\nDescription\nFrequency of Updates\nDimensions\nNotes\n\n\n\n\nML Hardware\nDataset listing hardward used to train ML models including GPUs, TPUs, and other less common hardware types\nDaily\n170 rows, 38 columns\n\n\n\nGPU Clusters\nDataset listing planned, existing, and previous GPU clusters\nDaily\n786 rows, 55 columns\nDaily refreshes, but data may not necesarily be updated daily.\n\n\nAI Companies\nVarious different datasets pertaining to AI company revenue, compute spend, staffing, funding rounds, user usage, and general information\nDaily\nVarious datasets\n\n\n\nAI Models\nDataset listing AI models over the years (including primitive models)\nDaily\n3000+ rows, 56 columns\nDivided into “Frontier”, “Notable”, and “Large Scale” models\n\n\nAI Benchmark Data\nA collection of different datasets of ML model performance on different benchmarks\nnot found\nVarious datasets\n\n\n\n\nPlease see links above for finer details on the datasets.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#other-problems-and-limitations-of-the-data",
    "href": "data.html#other-problems-and-limitations-of-the-data",
    "title": "2  Data",
    "section": "2.3 Other problems and limitations of the data",
    "text": "2.3 Other problems and limitations of the data\n\ninconsistent location format in the GPU cluster dataset",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  }
]